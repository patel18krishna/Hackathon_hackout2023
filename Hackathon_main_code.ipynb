{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code shows the logic of our behind the main idea. Basically its the most important logic of our backend. At some places some hypothetic values are taken. In real time we will fetch the data from our main database but because of platform dependencies we could not connect the database. Though we have designed hypothetic database and it will be shared with the code."
      ],
      "metadata": {
        "id": "n_bzhwbjhep5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "53BVLtgAmJwd"
      },
      "outputs": [],
      "source": [
        "#importing important libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython import get_ipython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function of our Deep learning model\n",
        "#this model is trained with very limited amount of information because of data constraint\n",
        "#The data set which is used to train this model is covid patient dataset from Mexico.\n",
        "def ml_model_and_predict(new_input):\n",
        "  # Importing important libraries\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  from google.colab import files\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "\n",
        "  # Load the dataset\n",
        "  uploaded = files.upload()\n",
        "  dataset = pd.read_csv(\"covid.csv\")\n",
        "\n",
        "  # Splited data into features (X) and target (y)\n",
        "  X = dataset[['sex', 'pneumonia', 'age', 'diabetes', 'asthma', 'hypertension', 'other_disease', 'cardiovascular', 'obesity', 'tobacco']]\n",
        "  y = dataset['Result']\n",
        "\n",
        "  # Split data into training and testing sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  #  Building the MLP model\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  # Compiling the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Training the model\n",
        "  model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.1)\n",
        "\n",
        "  #while training it gave accuracy of 0.8661 on training dataset\n",
        "  # Evaluating the model on the testing set\n",
        "  test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "  print(\"Test Loss:\", test_loss)\n",
        "  print(\"Test Accuracy:\", test_accuracy)\n",
        "  #it gave accuracy of 0.8460000157356262\n",
        "\n",
        "  # Make prediction using the trained model\n",
        "  prediction = model.predict(user_input)\n",
        "\n",
        "  # Interpret the prediction and provide output to the user\n",
        "  if prediction[0][0] >= 0.5:\n",
        "    result = \"Urgent\"\n",
        "  else:\n",
        "    result = \"Not urgent\"\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "oLoRY6vL_luo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking_input from user\n",
        "new_input = {\n",
        "    'name': input('Enter your name'),\n",
        "    'age': input('Enter age: '),\n",
        "    'location': str(input('Enter location')),\n",
        "    'gender': input('Enter gender (0 if you are male, 1 if you are female'),\n",
        "    'pneumonia': input('1 if you have pneumonia  or else 0'),\n",
        "    'diabetes': input('1 if you have diabetes problem or else 0'),\n",
        "    'asthma': input('1 if you have asthma problem or else 0'),\n",
        "    'hypertension': input('1 if you have hypertension problem or else 0'),\n",
        "    'other_disease': input('1 if you have other_disease or else 0'),\n",
        "    'cardiovascular': input('1 if you have cardiovascular complication or else 0'),\n",
        "    'obesity': input('1 if you have obesity or else 0'),\n",
        "    'tobacco': input('1 if you eat tobacco or else 0'),\n",
        "    'current_problem': input('write your health issue in short')\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX-TQWSbmWcF",
        "outputId": "74fffc54-6207-4f94-ca9f-cdbf2060a66f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your namekrishna\n",
            "Enter age: 20\n",
            "Enter locationsargasan\n",
            "Enter gender (0 if you are male, 1 if you are female1\n",
            "1 if you have pneumonia  or else 00\n",
            "1 if you have diabetes problem or else 00\n",
            "1 if you have asthma problem or else 00\n",
            "1 if you have hypertension problem or else 00\n",
            "1 if you have other_disease or else 00\n",
            "1 if you have cardiovascular complication or else 00\n",
            "1 if you have obesity or else 00\n",
            "1 if you eat tobacco or else 00\n",
            "write your health issue in shortbreathing problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting user input to appropriate data types\n",
        "new_input['gender'] = int(new_input['gender'])\n",
        "new_input['pneumonia'] = int(new_input['pneumonia'])\n",
        "new_input['age'] = float(new_input['age'])\n",
        "new_input['diabetes'] = int(new_input['diabetes'])\n",
        "new_input['asthma'] = int(new_input['asthma'])\n",
        "new_input['hypertension'] = int(new_input['hypertension'])\n",
        "new_input['other_disease'] = int(new_input['other_disease'])\n",
        "new_input['cardiovascular'] = int(new_input['cardiovascular'])\n",
        "new_input['obesity'] = int(new_input['obesity'])\n",
        "new_input['tobacco'] = int(new_input['tobacco'])\n",
        "new_input['name'] = str(new_input['name'])\n",
        "new_input['current_problem'] = str(new_input['current_problem'])"
      ],
      "metadata": {
        "id": "GSTKX8j2vHzW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it`s a main function to convert the input in needed form and pass it through the model and get prediction from the output\n",
        "if __name__ == '__main__':\n",
        "  # Creating a NumPy array for input features for DL model\n",
        "  user_input = np.array([\n",
        "    new_input['gender'],\n",
        "    new_input['pneumonia'],\n",
        "    new_input['age'],\n",
        "    new_input['diabetes'],\n",
        "    new_input['asthma'],\n",
        "    new_input['hypertension'],\n",
        "    new_input['other_disease'],\n",
        "    new_input['cardiovascular'],\n",
        "    new_input['obesity'],\n",
        "    new_input['tobacco']])\n",
        "\n",
        "  # Reshape input to match the model's input shape\n",
        "  user_input = user_input.reshape(1, -1)\n",
        "\n",
        "  # Make prediction using the trained model\n",
        "  prediction = ml_model_and_predict(user_input)\n",
        "  print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sQJdRTiUrqRR",
        "outputId": "7bcbe739-b349-4024-99d2-6d51c794c80a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3c1dfef7-e37c-4fb6-b6d5-05da216730b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3c1dfef7-e37c-4fb6-b6d5-05da216730b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving covid.csv to covid.csv\n",
            "Epoch 1/40\n",
            "113/113 [==============================] - 2s 7ms/step - loss: 0.5678 - accuracy: 0.8258 - val_loss: 0.4776 - val_accuracy: 0.8225\n",
            "Epoch 2/40\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 0.4439 - accuracy: 0.8338 - val_loss: 0.4104 - val_accuracy: 0.8225\n",
            "Epoch 3/40\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8327 - val_loss: 0.3573 - val_accuracy: 0.8600\n",
            "Epoch 4/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8352 - val_loss: 0.3486 - val_accuracy: 0.8425\n",
            "Epoch 5/40\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8419 - val_loss: 0.3562 - val_accuracy: 0.8300\n",
            "Epoch 6/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8430 - val_loss: 0.3969 - val_accuracy: 0.8225\n",
            "Epoch 7/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8544 - val_loss: 0.3391 - val_accuracy: 0.8400\n",
            "Epoch 8/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8500 - val_loss: 0.3204 - val_accuracy: 0.8650\n",
            "Epoch 9/40\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8463 - val_loss: 0.3197 - val_accuracy: 0.8575\n",
            "Epoch 10/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8522 - val_loss: 0.3366 - val_accuracy: 0.8600\n",
            "Epoch 11/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8519 - val_loss: 0.3621 - val_accuracy: 0.8425\n",
            "Epoch 12/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8422 - val_loss: 0.3272 - val_accuracy: 0.8350\n",
            "Epoch 13/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8538 - val_loss: 0.4003 - val_accuracy: 0.8225\n",
            "Epoch 14/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8500 - val_loss: 0.3135 - val_accuracy: 0.8550\n",
            "Epoch 15/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8608 - val_loss: 0.3517 - val_accuracy: 0.8225\n",
            "Epoch 16/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8572 - val_loss: 0.3246 - val_accuracy: 0.8325\n",
            "Epoch 17/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8583 - val_loss: 0.3141 - val_accuracy: 0.8550\n",
            "Epoch 18/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8530 - val_loss: 0.3103 - val_accuracy: 0.8600\n",
            "Epoch 19/40\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8580 - val_loss: 0.3406 - val_accuracy: 0.8275\n",
            "Epoch 20/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8538 - val_loss: 0.3127 - val_accuracy: 0.8650\n",
            "Epoch 21/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8594 - val_loss: 0.3882 - val_accuracy: 0.8225\n",
            "Epoch 22/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3157 - accuracy: 0.8536 - val_loss: 0.3286 - val_accuracy: 0.8275\n",
            "Epoch 23/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8577 - val_loss: 0.3063 - val_accuracy: 0.8600\n",
            "Epoch 24/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8550 - val_loss: 0.3134 - val_accuracy: 0.8675\n",
            "Epoch 25/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3153 - accuracy: 0.8533 - val_loss: 0.3146 - val_accuracy: 0.8700\n",
            "Epoch 26/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8566 - val_loss: 0.3272 - val_accuracy: 0.8400\n",
            "Epoch 27/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8525 - val_loss: 0.3373 - val_accuracy: 0.8300\n",
            "Epoch 28/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8552 - val_loss: 0.3103 - val_accuracy: 0.8600\n",
            "Epoch 29/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8555 - val_loss: 0.3173 - val_accuracy: 0.8625\n",
            "Epoch 30/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8639 - val_loss: 0.3125 - val_accuracy: 0.8575\n",
            "Epoch 31/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8600 - val_loss: 0.3097 - val_accuracy: 0.8550\n",
            "Epoch 32/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8614 - val_loss: 0.3478 - val_accuracy: 0.8300\n",
            "Epoch 33/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8563 - val_loss: 0.3198 - val_accuracy: 0.8500\n",
            "Epoch 34/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8611 - val_loss: 0.3093 - val_accuracy: 0.8600\n",
            "Epoch 35/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8627 - val_loss: 0.3120 - val_accuracy: 0.8650\n",
            "Epoch 36/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8591 - val_loss: 0.3100 - val_accuracy: 0.8650\n",
            "Epoch 37/40\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8639 - val_loss: 0.3552 - val_accuracy: 0.8275\n",
            "Epoch 38/40\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8552 - val_loss: 0.3125 - val_accuracy: 0.8600\n",
            "Epoch 39/40\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.8563 - val_loss: 0.3260 - val_accuracy: 0.8400\n",
            "Epoch 40/40\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 0.3164 - accuracy: 0.8547 - val_loss: 0.3251 - val_accuracy: 0.8600\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8250\n",
            "Test Loss: 0.36869150400161743\n",
            "Test Accuracy: 0.824999988079071\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "Prediction: Urgent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for suggesting hospitals or clinic near your location and showing information about that hospital/clinic ex.mediclaim type, available beds\n",
        "hospital_location = np.array(['sargasan', 'sargasan', 'sargasan']) #import locations of hospitals here\n",
        "near_hospital_list = []\n",
        "print(new_input['location'])\n",
        "for i in hospital_location:\n",
        "  if new_input['location'] == i:\n",
        "    near_hospital_list.append(i)\n",
        "print(near_hospital_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaXvAVmCr18w",
        "outputId": "c5c45ad4-8eda-413e-aaa2-023712fcadc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sargasan\n",
            "['sargasan', 'sargasan', 'sargasan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we want a shared room with cashless mediclaim. So, we are going with 2nd hospital. It could be made automated  with frontend but we are presenting frontend with GUI."
      ],
      "metadata": {
        "id": "zrA4tmH-3Z21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import available_events\n",
        "if prediction == \"Urgent\":\n",
        "  #messege/ notification to assitant staff\n",
        "  print(\"ASSISTANT STAFF\")\n",
        "  print(\"**URGENT CASE**\")\n",
        "  print(\"A patient from near by area has emergency. Patient will be here in short period of time. Some details are attached below.\")\n",
        "  print(\"GENDER \", new_input['gender'])\n",
        "  print(\"SYNPTONS \", new_input['pneumonia'])\n",
        "  print(\"AGE \", new_input['age'])\n",
        "  print(\"DIABETES \", new_input['diabetes'])\n",
        "  print(\"ASTHMA PROBLEM \", new_input['asthma'])\n",
        "  print(\"HYPTERTENTION PROBLEM \", new_input['hypertension'])\n",
        "  print(\"OTHER DISEASE \", new_input['other_disease'])\n",
        "  print(\"CARDIOVASCULAR PROBLEM \", new_input['cardiovascular'])\n",
        "  print(\"OBESITY\", new_input['obesity'])\n",
        "  print(\"TOBACCO\", new_input['tobacco'])\n",
        "  #To find a doctor to handle urgent case\n",
        "  #below data will be fetched from database with query\n",
        "  urgency_level_of_doctors_appointment = np.array(['Urgent','non-Urgent','Urgent','non-Urgent','Urgent'])\n",
        "  available_doctors = []\n",
        "  for i in urgency_level_of_doctors_appointment:\n",
        "    if i == None:\n",
        "      available_doctors.append(i.index)\n",
        "    elif i == 'non-Urgent':\n",
        "      available_doctors.append(i.index)\n",
        "  #To show available doctors\n",
        "  print(available_doctors)\n",
        "  #hypothetically sending below details to above list of doctors\n",
        "  for i in available_doctors:\n",
        "    print(i)\n",
        "    print(\"Doctor!!\")\n",
        "    print(\"**URGENT CASE**\")\n",
        "    print(\"A patient from near by area has emergency. Patient will be here in short period of time. Some details are attached below.\")\n",
        "    print(\"NAME\", new_input['name'])\n",
        "    print(\"GENDER \", new_input['gender'])\n",
        "    print(\"SYNPTONS \", new_input['pneumonia'])\n",
        "    print(\"AGE \", new_input['age'])\n",
        "    print(\"DIABETES \", new_input['diabetes'])\n",
        "    print(\"ASTHMA PROBLEM \", new_input['asthma'])\n",
        "    print(\"HYPTERTENTION PROBLEM \", new_input['hypertension'])\n",
        "    print(\"OTHER DISEASE \", new_input['other_disease'])\n",
        "    print(\"CARDIOVASCULAR PROBLEM \", new_input['cardiovascular'])\n",
        "    print(\"OBESITY\", new_input['obesity'])\n",
        "    print(\"TOBACCO\", new_input['tobacco'])\n",
        "else:\n",
        "  doctors_in_2nd_hospital = np.array([\"Harvi Patel\", \"Bhoomi Barot\", \"Krishna Patel\", \"Jay Oza\"])\n",
        "  Doc_name_input = {\n",
        "    'Select_doctor': int(input('Enter your selection with integer'))\n",
        "  }\n",
        "  if Doc_name_input['Select_doctor'] == 1:\n",
        "    doctor = \"Harvi Patel\"\n",
        "  elif Doc_name_input['Select_doctor'] == 2:\n",
        "    doctor = \"Bhoomi Barot\"\n",
        "  elif Doc_name_input['Select_doctor'] == 3:\n",
        "    doctor = \"Krishna Patel\"\n",
        "  elif Doc_name_input['Select_doctor'] == 4:\n",
        "    doctor = \"Jay Oza\"\n",
        "  print(doctor)\n",
        "  #hypothetically available slots of selected doctor are shown below in real project it will be fetched from database\n",
        "  available_slots = np.array([\"9:15\", \"11:00\", \"3:40\", \"5:45\"])\n",
        "  print(available_slots)\n",
        "  #the user can select any  of them and book the appointment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay-onjZHwnqJ",
        "outputId": "d730f01c-438c-4fef-f4ec-af3a160e6138"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASSISTANT STAFF\n",
            "**URGENT CASE**\n",
            "A patient from near by area has emergency. Patient will be here in short period of time. Some details are attached below.\n",
            "GENDER  1\n",
            "SYNPTONS  0\n",
            "AGE  20.0\n",
            "DIABETES  0\n",
            "ASTHMA PROBLEM  0\n",
            "HYPTERTENTION PROBLEM  0\n",
            "OTHER DISEASE  0\n",
            "CARDIOVASCULAR PROBLEM  0\n",
            "OBESITY 0\n",
            "TOBACCO 0\n",
            "[<built-in method index of numpy.str_ object at 0x7d25c06c22b0>, <built-in method index of numpy.str_ object at 0x7d25c06c2670>]\n",
            "<built-in method index of numpy.str_ object at 0x7d25c06c22b0>\n",
            "Doctor!!\n",
            "**URGENT CASE**\n",
            "A patient from near by area has emergency. Patient will be here in short period of time. Some details are attached below.\n",
            "NAME krishna\n",
            "GENDER  1\n",
            "SYNPTONS  0\n",
            "AGE  20.0\n",
            "DIABETES  0\n",
            "ASTHMA PROBLEM  0\n",
            "HYPTERTENTION PROBLEM  0\n",
            "OTHER DISEASE  0\n",
            "CARDIOVASCULAR PROBLEM  0\n",
            "OBESITY 0\n",
            "TOBACCO 0\n",
            "<built-in method index of numpy.str_ object at 0x7d25c06c2670>\n",
            "Doctor!!\n",
            "**URGENT CASE**\n",
            "A patient from near by area has emergency. Patient will be here in short period of time. Some details are attached below.\n",
            "NAME krishna\n",
            "GENDER  1\n",
            "SYNPTONS  0\n",
            "AGE  20.0\n",
            "DIABETES  0\n",
            "ASTHMA PROBLEM  0\n",
            "HYPTERTENTION PROBLEM  0\n",
            "OTHER DISEASE  0\n",
            "CARDIOVASCULAR PROBLEM  0\n",
            "OBESITY 0\n",
            "TOBACCO 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THANK YOU!"
      ],
      "metadata": {
        "id": "h-Qmx6UOkeO8"
      }
    }
  ]
}